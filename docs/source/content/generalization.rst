.. _generalization-introduction:

Splam generalizes on non-human species
=========================================================================

If you are considering improving your non-human RNA-Seq alignment files or transcript assemblies and wondering whether Splam is the right tool to use, this page provides the answer!

In short, the answer is **Yes âœ…**!

You can perform the same analysis as described in the :ref:`alignment-detailed-section` and :ref:`annotation-detailed-section` pages. All you need to prepare are the **(1) genome**, and **(2) alignment files or annotation files** of the species you are interested in.

Below is a simple example to show :ref:`Splam works on mouse <example_on_running_splam_on_mouse>` and a detailed explanation on :ref:`how well Splam works on non-human species <splam_generalization_performance>`. 

|


.. _example_on_running_splam_on_mouse:
An example of running Splam on house mouse (*Mus musculus*) 
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

|


.. _splam_generalization_performance:
Splam's performance on non-human species
++++++++++++++++++++++++++++++++++++++++++++

Although Splam was trained on human datasets, we have shown that the model is able to generalize to other eukaryotic genomes, including plants. In our investigation, we tested the performance of Splam on the Chimpanzee (*Pan troglodytes*), Mouse (*Mus musculus*), and Thale cress, a flowering plant (*Arabidopsis thaliana*), genomes. We report that Splam outperforms SpliceAI in recall, precision, and accuracy, on every score threshold for every species. Additionally, we propose two workflows for running Splam on non-human species: 

.. _generalization-data-curation:

Data curation 
----------------

For each species, we curated our positive and negative datasets similar to the Positive-MANE and Negative-Random strategies from :ref:`behind-the-scenes-splam`. The positive dataset was generated from the complete Refseq/TAIR annotation files downloaded from NCBI, where we extracted the introns from every transcript, filtered out poor annotations, and saved the remaining ~200k as splice junctions. The negative dataset was generated by randomly selecting variable-length canonical GT-AG pairs from the opposite strand of protein-coding genes. 

For both datasets, we randomly sampled 25,000 splice junctions and ran Splam and SpliceAI on them to compare results.


|

.. _generalization-key-findings:

Key findings
----------------

We find that Splam is able to quickly and accurately classify positive and negative samples, even in species as distant as plants (*Arabidopsis thaliana*). For the positive samples, Splam correctly classified the vast majority with a high score, whereas SpliceAI struggled more, particularly with *Arabidopsis*. Moreover, we find that Splam is decisive, with medians values for all three species at 1.0, while SpliceAI's distribution is more evenly spread (:numref:`generalization-score-dist`). 

.. _generalization-score-dist:
.. figure::  ../_images/generalization_pos_score_dist.png
   :align:   center
   :scale:   8 %

   A comparison of the score distributions between Splam (green) and SpliceAI (orange) for the positive dataset. The top row represents donor site scores and the bottom row represents acceptor site scores. The darkened vertical line through the distribution represents the median value, while the two dotted vertical lines represent the first and third quartiles. Splam demonstrates the ability to correctly score positive samples highly, with a peak near 1.0 for all three species. SpliceAI's distributions are more spread out, especially for *Arabidopsis*, which exhibits an M-shaped distribution.

|

Combining this result with the negative data, we calculate summary statistics that help us gauge the performance of Splam at various thresholds. We observe that the recall/sensitivity, precision, and accuracy of Splam outperform SpliceAI at every score threshold for every species, visualized in :numref:`generalization-heatmap`. Additionally, the figure demonstrates Splam's consistency across a wide range of score thresholds. 

.. _generalization-heatmap:
.. figure::  ../_images/generalization_performance_heatmap.png
   :align:   center
   :scale:   22 %

   A grid of heatmaps portraying the recall (top), precision (middle), and accuracy (bottom) of both models on the chimpanzee (left), mouse (middle), and *Arabidopsis* (right) genomes, across a variety of score thresholds (x-axis). For each heatmap, the top three rows (green) represent Splam, and the bottom three rows (orange) represent SpliceAI, where each is examined at the donor, acceptor, and splice junction levels. The performance metrics are reported as percentages on the heatmap. We observe that Splam exhibits consistently high recall and accuracy whereas SpliceAI's swiftly declines with increasing score thresholds. Precision for both models is consistently high. 

|

The results of this investigation demonstrate Splam's ability to generalize well on non-human species, including both animal and plant genomes. Additionally, we show Splam performing consistently and accurately on a wide range of score thresholds. 

|
|
|
|
|

.. image:: ../_images/jhu-logo-dark.png
   :alt: My Logo
   :class: logo, header-image only-light
   :align: center

.. image:: ../_images/jhu-logo-white.png
   :alt: My Logo
   :class: logo, header-image only-dark
   :align: center